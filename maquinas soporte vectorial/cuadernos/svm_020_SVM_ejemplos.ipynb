{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285898ac-6b28-403c-8b77-ca4e3abe186a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure> \n",
    "<img src=\"../imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc966d7-5796-48a3-8298-ef1513d33f93",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Máquinas de Soporte Vectorial<center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8bf36-5a6f-4ece-b688-bbd1f70be59c",
   "metadata": {},
   "source": [
    "<figure> \n",
    "<center>\n",
    "<img src=\"../imagenes/animacion_svm.gif\"  width=\"600\" height=\"600\" align=\"center\"/>\n",
    "<figcaption> Reflejos</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Fuente [Zahra Elhamraoui](https://medium.datadriveninvestor.com/support-vector-machine-svm-algorithm-in-a-fun-easy-way-fc23a008c22), vía [Medium](https://medium.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae5ae4-23df-405d-81c4-47a6d2029cd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da81425-7177-40df-868f-e13afa55a651",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "1. [Cristianini, N. and Shawe-Taylor, J., An intorduction to Support vector MAchines and other learning methods, Cambridge, 16th printing, 2014 ](http://library.lol/main/B775D59309583D4894A445C20721F8BF)\n",
    "1. [Shawe-Taylor, J. and Cristianini, N., Kernel Methods for pattern analysis, Cambridge, 2004](https://libgen.rocks/ads.php?md5=9A2BEA22F1D8CD3BB8B6F99D22D4DCF0)\n",
    "1. [Scikit learn-SVM](https://scikit-learn.org/stable/modules/svm.html#svm-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93bdd1b-fbc0-464a-9645-988015cfd880",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201bd4e-8bd2-463a-920a-2c8ee1495fe4",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Campo Elías Pardo, PhD, cepardot@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dammontenegrore@unal.edu.co\n",
    "1. Oleg Jarma, Estadístico, ojarmam@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca278402-3c25-4a4f-981d-aeab84bf59ef",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asesora de medios y marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5c52d-8940-4633-86b6-32756b881968",
   "metadata": {},
   "source": [
    "1. Maria del Pilar Montenegro, pmontenegro88@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a73ad-dbe8-425c-8034-5216577da84a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930a515-28b3-4bc7-a228-402a1f5e1988",
   "metadata": {},
   "source": [
    "Esta sección está basada principalmente en [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine). En el aprendizaje automático, las máquinas de vectores de soporte (SVM), de support vector machine en inglés, son modelos de aprendizaje supervisado con algoritmos de aprendizaje asociados que analizan datos para clasificación y análisis de regresión. Desarrollado en AT&T Bell Laboratories por Vladimir Vapnik con varios colegas como (Boser et al., 1992, Guyon et al., 1993, Cortes and Vapnik, 1995,  Vapnik et al., 1997).\n",
    "\n",
    "Las SVM son uno de los métodos de predicción más robustos, basados en marcos de aprendizaje estadístico o teoría VC propuesta por Vapnik (1982, 1995) y Chervonenkis (1974). Dado un conjunto de ejemplos de entrenamiento, cada uno marcado como perteneciente a una de dos categorías, un algoritmo de entrenamiento SVM construye un modelo que asigna nuevos ejemplos a una categoría u otra, convirtiéndolo en un clasificador lineal binario no probabilístico.  SVM asigna ejemplos de entrenamiento a puntos en el espacio para maximizar el ancho de la brecha entre las dos categorías. Luego, los nuevos ejemplos se mapean en ese mismo espacio y se predice que pertenecen a una categoría según el lado de la brecha en el que se encuentran.\n",
    "\n",
    "Además de realizar una clasificación lineal, las SVM pueden realizar de manera eficiente una clasificación no lineal utilizando lo que se denomina el truco del kernel, mapeando implícitamente sus entradas en espacios de características de alta dimensión.\n",
    "\n",
    "Para los detalles teóricos consulte la lección [SVM](\"svm_010_Intro_SVM.ipynb\"). El algoritmo clásico es descrito en la siguiente sección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2997c32-5acd-4868-859f-feb39686b37a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Regularización</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cc08e-16f7-42be-838a-e34cbf22d1d5",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Parámetro C </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856be65e-3456-43c6-a92d-91fba79ea7d4",
   "metadata": {},
   "source": [
    "\n",
    "El parámetro de Regularización (a menudo denominado como parámetro C en la biblioteca sklearn de python) le dice a la optimización de SVM cuánto quiere evitar clasificar erróneamente cada ejemplo de entrenamiento.\n",
    "\n",
    "Para valores grandes de C, la optimización elegirá un hiperplano de margen más pequeño si ese hiperplano hace un mejor trabajo al clasificar correctamente todos los puntos de entrenamiento. Por el contrario, un valor muy pequeño de C hará que el optimizador busque un hiperplano de separación de mayor margen, incluso si ese hiperplano clasifica incorrectamente más puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435bab1-ba07-4df3-9906-fcd0eda06eec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Parámetro gamma </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac7c5a-3659-4eef-995c-09724ea6712f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Gamma se usa cuando usamos el kernel Gaussian RBF. si usa un núcleo lineal o polinomial, entonces no necesita gamma, solo necesita un hipermetro C. En algún lugar también se usa como sigma. En realidad, sigma y gamma están relacionados de la siguiente forma\n",
    "\n",
    "$$\n",
    "\\gamma = \\frac{1}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "Gamma decide cuánta curvatura queremos en un límite de decisión.\n",
    "\n",
    "* Gamma alto significa más curvatura.\n",
    "* Gamma bajo significa menos curvatura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93472672-e1aa-4d25-8548-9be642ac62da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\"> El ejemplo de clasificación con los datos de Iris con scikit learn</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9b46f-4269-4eed-8e9f-0739ad953047",
   "metadata": {},
   "source": [
    "Este es un ejemplo típico de la estadística: el conjunto de datos iris. Por comodidad usaremos únicamente dos clases. El ejemplo es tomado de los [tutoriales de sklearn](https://scikit-learn.org/stable/modules/classes.html?highlight=svm#module-sklearn.svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1557e-f65f-49dc-843d-d6097e7903fb",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Lectura de datos y entrenamiento del modelo</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
